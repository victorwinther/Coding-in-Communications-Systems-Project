{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from scipy.fftpack import dct, idct\n",
    "from heapq import heapify,heappop, heappush\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio.v3 as iio\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_ycbcr(image):\n",
    "    \"\"\"\n",
    "    Convert an RGB image to YCbCr and return separate Y, Cb, and Cr images.\n",
    "    Parameters: a PIL Image object in RGB mode.\n",
    "    Returns: Y, Cb, Cr: numpy arrays representing the Y, Cb, and Cr components.\n",
    "    \"\"\"\n",
    "    img_array = np.array(image, dtype=float)\n",
    "    \n",
    "    # Separate the RGB channels\n",
    "    R = img_array[:, :, 0]\n",
    "    G = img_array[:, :, 1]\n",
    "    B = img_array[:, :, 2]\n",
    "    \n",
    "    Y = 0.299 * R + 0.587 * G + 0.114 * B\n",
    "    Cb = 128 - 0.168736 * R - 0.331264 * G + 0.5 * B\n",
    "    Cr = 128 + 0.5 * R - 0.418688 * G - 0.081312 * B\n",
    "    \n",
    "    return Y, Cb, Cr\n",
    "\n",
    "def save_component_image(component, filename):\n",
    "    \"\"\"\n",
    "    Save a single Y, Cb, or Cr component as an image.\n",
    "    \n",
    "    Parameters:\n",
    "    - component: a numpy array representing the Y, Cb, or Cr component.\n",
    "    - filename: the name of the file to save the image as.\n",
    "    \"\"\"\n",
    "    component_uint8 = np.uint8(component)\n",
    "    component_pil = Image.fromarray(component_uint8)\n",
    "    component_pil.save(filename)\n",
    "\n",
    "def apply_420_subsampling(Cb, Cr):\n",
    "    \"\"\"\n",
    "    Apply 4:2:0 subsampling to the Cb and Cr components.\n",
    "    \n",
    "    Parameters:\n",
    "    - Cb: numpy array representing the Cb component.\n",
    "    - Cr: numpy array representing the Cr component.\n",
    "    \n",
    "    Returns:\n",
    "    - Cb_subsampled, Cr_subsampled: numpy arrays representing the subsampled Cb and Cr components.\n",
    "    \"\"\"\n",
    "    # Perform 4:2:0 subsampling\n",
    "    Cb_subsampled = Cb[::2, ::2]  # Take every second row and column\n",
    "    Cr_subsampled = Cr[::2, ::2]  # Take every second row and column\n",
    "    \n",
    "    return Cb_subsampled, Cr_subsampled\n",
    "\n",
    "def ycbcr_to_rgb(Y, Cb_subsampled, Cr_subsampled):\n",
    "    \"\"\"\n",
    "    Convert YCbCr components back to RGB.\n",
    "    \n",
    "    Parameters:\n",
    "    - Y: numpy array representing the Y component.\n",
    "    - Cb_subsampled: numpy array representing the subsampled Cb component.\n",
    "    - Cr_subsampled: numpy array representing the subsampled Cr component.\n",
    "    \n",
    "    Returns:\n",
    "    - rgb_image: PIL Image object representing the reconstructed RGB image.\n",
    "    \"\"\"\n",
    "    # Upsample Cb and Cr components to match Y size (repeat rows and columns)\n",
    "    height, width = Y.shape\n",
    "    Cb_upsampled = np.repeat(np.repeat(Cb_subsampled, 2, axis=0), 2, axis=1)\n",
    "    Cr_upsampled = np.repeat(np.repeat(Cr_subsampled, 2, axis=0), 2, axis=1)\n",
    "    \n",
    "    # Perform inverse YCbCr to RGB conversion\n",
    "    R = Y + 1.402 * (Cr_upsampled - 128)\n",
    "    G = Y - 0.344136 * (Cb_upsampled - 128) - 0.714136 * (Cr_upsampled - 128)\n",
    "    B = Y + 1.772 * (Cb_upsampled - 128)\n",
    "    \n",
    "    # Stack R, G, B channels and clip values to [0, 255]\n",
    "    rgb_image = np.stack((R, G, B), axis=-1)\n",
    "    rgb_image = np.clip(rgb_image, 0, 255)\n",
    "    rgb_image = np.uint8(rgb_image)\n",
    "    \n",
    "    # Convert numpy array to PIL Image\n",
    "    rgb_image_pil = Image.fromarray(rgb_image)\n",
    "    \n",
    "    return rgb_image_pil\n",
    "# Example usage:\n",
    "image_path = 'sample.bmp'\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "Y, Cb, Cr = rgb_to_ycbcr(image)\n",
    "\n",
    "# Save the Y, Cb, and Cr images\n",
    "# save_component_image(Y, 'Y_component.bmp')\n",
    "# save_component_image(Cb, 'Cb_component.bmp')\n",
    "# save_component_image(Cr, 'Cr_component.bmp')\n",
    "\n",
    "# To visualize the components\n",
    "#Image.fromarray(np.uint8(Y)).show(title=\"Y Component\")\n",
    "#Image.fromarray(np.uint8(Cb)).show(title=\"Cb Component\")\n",
    "#Image.fromarray(np.uint8(Cr)).show(title=\"Cr Component\")\n",
    "\n",
    "\n",
    "Cb_subsampled, Cr_subsampled = apply_420_subsampling(Cb, Cr)\n",
    "# Visualize the original and subsampled Cb and Cr components\n",
    "#Image.fromarray(np.uint8(Cb)).show(title=\"Original Cb Component\")\n",
    "#Image.fromarray(np.uint8(Cb_subsampled)).show(title=\"Subsampled Cb Component\")\n",
    "\n",
    "#Image.fromarray(np.uint8(Cr)).show(title=\"Original Cr Component\")\n",
    "#Image.fromarray(np.uint8(Cr_subsampled)).show(title=\"Subsampled Cr Component\")\n",
    "\n",
    "# Convert YCbCr components back to RGB\n",
    "#reconstructed_rgb_image = ycbcr_to_rgb(Y, Cb_subsampled, Cr_subsampled)\n",
    "\n",
    "# Display the reconstructed RGB image\n",
    "#reconstructed_rgb_image.show(title=\"Reconstructed RGB Image\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_table_luminance = np.array([\n",
    "    [16, 11, 10, 16, 24, 40, 51, 61],\n",
    "    [12, 12, 14, 19, 26, 58, 60, 55],\n",
    "    [14, 13, 16, 24, 40, 57, 69, 56],\n",
    "    [14, 17, 22, 29, 51, 87, 80, 62],\n",
    "    [18, 22, 37, 56, 68, 109, 103, 77],\n",
    "    [24, 35, 55, 64, 81, 104, 113, 92],\n",
    "    [49, 64, 78, 87, 103, 121, 120, 101],\n",
    "    [72, 92, 95, 98, 112, 100, 103, 99]\n",
    "])\n",
    "\n",
    "quant_table_chrominance = np.array([\n",
    "    [17, 18, 24, 47, 99, 99, 99, 99],\n",
    "    [18, 21, 26, 66, 99, 99, 99, 99],\n",
    "    [24, 26, 56, 99, 99, 99, 99, 99],\n",
    "    [47, 66, 99, 99, 99, 99, 99, 99],\n",
    "    [99, 99, 99, 99, 99, 99, 99, 99],\n",
    "    [99, 99, 99, 99, 99, 99, 99, 99],\n",
    "    [99, 99, 99, 99, 99, 99, 99, 99],\n",
    "    [99, 99, 99, 99, 99, 99, 99, 99]\n",
    "])\n",
    "\n",
    "def quantize_dct(dct_block, quant_matrix):\n",
    "    return np.round(dct_block / quant_matrix)\n",
    "\n",
    "\n",
    "def block_process(channel, block_size, process_block, quant_matrix):\n",
    "    print(f\"Processing blocks of shape: {channel.shape}\")\n",
    "    h, w = channel.shape[:2]\n",
    "    blocks = (channel.reshape(h // block_size, block_size, -1, block_size)\n",
    "                      .swapaxes(1, 2)\n",
    "                      .reshape(-1, block_size, block_size))\n",
    "    processed_blocks = np.array([process_block(block) for block in blocks])\n",
    "    quantized_blocks = np.array([quantize_dct(block, quant_matrix) for block in processed_blocks])\n",
    "    return (quantized_blocks.reshape(h // block_size, w // block_size, block_size, block_size)\n",
    "                            .swapaxes(1, 2)\n",
    "                            .reshape(h, w))\n",
    "\n",
    "def dct2d_library(block):\n",
    "    return dct(dct(block.T, norm='ortho').T, norm='ortho')\n",
    "\n",
    "\n",
    "def dct2d_manual(block):\n",
    "    N = block.shape[0]\n",
    "    dct_matrix = np.zeros((N, N))\n",
    "\n",
    "    def alpha(u):\n",
    "        return np.sqrt(1/2) if u == 0 else 1\n",
    "\n",
    "    for u in range(N):\n",
    "        for v in range(N):\n",
    "            sum_value = 0.0\n",
    "            for x in range(N):\n",
    "                for y in range(N):\n",
    "                    sum_value += block[x, y] * np.cos((2 * x + 1) * u * np.pi / (2 * N)) * np.cos((2 * y + 1) * v * np.pi / (2 * N))\n",
    "            dct_matrix[u, v] = 0.25 * alpha(u) * alpha(v) * sum_value\n",
    "\n",
    "    return dct_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing blocks of shape: (1280, 1920)\n",
      "Processing blocks of shape: (640, 960)\n",
      "Processing blocks of shape: (640, 960)\n"
     ]
    }
   ],
   "source": [
    "Y_dct = block_process(Y, 8, dct2d_library, quant_table_luminance)\n",
    "Cb_dct = block_process(Cb_subsampled, 8, dct2d_library, quant_table_chrominance)\n",
    "Cr_dct = block_process(Cr_subsampled, 8, dct2d_library, quant_table_chrominance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image_path):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    Y, Cb, Cr = rgb_to_ycbcr(image)\n",
    "    Cb_subsampled, Cr_subsampled = apply_420_subsampling(Cb, Cr)\n",
    "\n",
    "    Y_dct = block_process(Y, 8, dct2d_library, quant_table_luminance)\n",
    "    Cb_dct = block_process(Cb_subsampled, 8, dct2d_library, quant_table_chrominance)\n",
    "    Cr_dct = block_process(Cr_subsampled, 8, dct2d_library, quant_table_chrominance)\n",
    "\n",
    "    return Y_dct, Cb_dct, Cr_dct\n",
    "\n",
    "class HuffmanNode:\n",
    "    def __init__(self, symbol, freq):\n",
    "        self.symbol = symbol\n",
    "        self.freq = freq\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        return self.freq < other.freq\n",
    "\n",
    "def build_huffman_tree(freq):\n",
    "    heap = [HuffmanNode(symbol, freq) for symbol, freq in freq.items()]\n",
    "    heapify(heap)\n",
    "\n",
    "    while len(heap) > 1:\n",
    "        node1 = heappop(heap)\n",
    "        node2 = heappop(heap)\n",
    "        merged = HuffmanNode(None, node1.freq + node2.freq)\n",
    "        merged.left = node1\n",
    "        merged.right = node2\n",
    "        heappush(heap, merged)\n",
    "\n",
    "    return heap[0]\n",
    "\n",
    "def generate_huffman_codes(node, prefix='', codebook={}):\n",
    "    if node is not None:\n",
    "        if node.symbol is not None:\n",
    "            codebook[node.symbol] = prefix\n",
    "        generate_huffman_codes(node.left, prefix + '0', codebook)\n",
    "        generate_huffman_codes(node.right, prefix + '1', codebook)\n",
    "    return codebook\n",
    "\n",
    "def huffman_encode(image):\n",
    "    hist, _ = np.histogram(image.flatten(), bins=256, range=[0,256])\n",
    "    freq = {i: hist[i] for i in range(256) if hist[i] > 0}\n",
    "    huffman_tree = build_huffman_tree(freq)\n",
    "    huffman_codes = generate_huffman_codes(huffman_tree)\n",
    "    encoded_image = ''.join([huffman_codes[pixel] for pixel in image.flatten()])\n",
    "    return encoded_image, huffman_codes\n",
    "\n",
    "# Afkod billedet og vis det\n",
    "def huffman_decode(encoded_image, huffman_codes, shape):\n",
    "    reverse_codes = {v: k for k, v in huffman_codes.items()}\n",
    "    decoded_image = []\n",
    "    buffer = ''\n",
    "    for bit in encoded_image:\n",
    "        buffer += bit\n",
    "        if buffer in reverse_codes:\n",
    "            decoded_image.append(reverse_codes[buffer])\n",
    "            buffer = ''\n",
    "    return np.array(decoded_image).reshape(shape)\n",
    "\n",
    "def Entropy(im):\n",
    "    histogram, bin_edges = np.histogram(im, bins=range(256))\n",
    "    p = histogram / np.sum(histogram)\n",
    "    p1 = p[p!=0]\n",
    "    entropy = -np.dot(p1.T,np.log2(p1))\n",
    "    return entropy\n",
    "\n",
    "def MSE(im1,im2):\n",
    "    return np.mean((im1-im2)**2)\n",
    "\n",
    "def PSNR(im1,im2):\n",
    "    mse = MSE(im1,im2)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    max_pixel = 2**8-1\n",
    "    psnr = 20 * np.log10(max_pixel / np.sqrt(mse))\n",
    "    return psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nedre grænse for gennemsnitlig kodelængde per pixel: 7.85 bits\n",
      "Processing blocks of shape: (1280, 1920)\n",
      "Processing blocks of shape: (640, 960)\n",
      "Processing blocks of shape: (640, 960)\n",
      "[72  1  0 ...  0  0  0]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "-1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m all_dct_coeffs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((Y_dct\u001b[38;5;241m.\u001b[39mflatten(), Cb_dct\u001b[38;5;241m.\u001b[39mflatten(), Cr_dct\u001b[38;5;241m.\u001b[39mflatten()))\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(all_dct_coeffs)\n\u001b[0;32m----> 8\u001b[0m encoded_data, huff_dict \u001b[38;5;241m=\u001b[39m \u001b[43mhuffman_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_dct_coeffs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m encoded_image, huffman_codes \u001b[38;5;241m=\u001b[39m huffman_encode(image)\n\u001b[1;32m     11\u001b[0m decoded_image \u001b[38;5;241m=\u001b[39m huffman_decode(encoded_image, huffman_codes, image\u001b[38;5;241m.\u001b[39mshape)\n",
      "Cell \u001b[0;32mIn[8], line 49\u001b[0m, in \u001b[0;36mhuffman_encode\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m     47\u001b[0m huffman_tree \u001b[38;5;241m=\u001b[39m build_huffman_tree(freq)\n\u001b[1;32m     48\u001b[0m huffman_codes \u001b[38;5;241m=\u001b[39m generate_huffman_codes(huffman_tree)\n\u001b[0;32m---> 49\u001b[0m encoded_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([huffman_codes[pixel] \u001b[38;5;28;01mfor\u001b[39;00m pixel \u001b[38;5;129;01min\u001b[39;00m image\u001b[38;5;241m.\u001b[39mflatten()])\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m encoded_image, huffman_codes\n",
      "Cell \u001b[0;32mIn[8], line 49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m huffman_tree \u001b[38;5;241m=\u001b[39m build_huffman_tree(freq)\n\u001b[1;32m     48\u001b[0m huffman_codes \u001b[38;5;241m=\u001b[39m generate_huffman_codes(huffman_tree)\n\u001b[0;32m---> 49\u001b[0m encoded_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[43mhuffman_codes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpixel\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m pixel \u001b[38;5;129;01min\u001b[39;00m image\u001b[38;5;241m.\u001b[39mflatten()])\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m encoded_image, huffman_codes\n",
      "\u001b[0;31mKeyError\u001b[0m: -1"
     ]
    }
   ],
   "source": [
    "image = iio.imread('sample.bmp')\n",
    "entropy_mountain = Entropy(image)\n",
    "print(f'Nedre grænse for gennemsnitlig kodelængde per pixel: {entropy_mountain:.2f} bits')\n",
    "\n",
    "Y_dct, Cb_dct, Cr_dct = process_image('sample.bmp')\n",
    "all_dct_coeffs = np.concatenate((Y_dct.flatten(), Cb_dct.flatten(), Cr_dct.flatten())).astype(int)\n",
    "print(all_dct_coeffs)\n",
    "encoded_data, huff_dict = huffman_encode(all_dct_coeffs)\n",
    "\n",
    "encoded_image, huffman_codes = huffman_encode(image)\n",
    "decoded_image = huffman_decode(encoded_image, huffman_codes, image.shape)\n",
    "entropy_mountain = Entropy(decoded_image)\n",
    "plt.imshow(decoded_image)\n",
    "plt.title('Afkodet Huffman billede')\n",
    "plt.show()\n",
    "print(f'Gennemsnitlig kodelængde per pixel: {len(encoded_image) / image.size:.2f} bits')\n",
    "print(f'Entropi: {entropy_mountain:.2f} bits')\n",
    "print(f'MSE: {MSE(image, decoded_image):.2f}')\n",
    "print(f'PSNR: {PSNR(image, decoded_image):.2f} dB')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Jesper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
